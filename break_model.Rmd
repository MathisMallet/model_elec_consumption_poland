---
title: "model_conso_elec_poland"
output:
  pdf_document: default
  html_document: default
date: "2026-01-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# To do : 

ajout de variable : indice de temp

Model prix elec réel <- prix_elec_passé + prop ENR + régulation type ETS ?

# Modèle de la consomation d'électricité en Pologne

## Libraires
```{r}
library(openxlsx)
library(tidyverse)
library(data.table)   
library(e1071)
library(lmtest)
library(sandwich)
library(nlme)
library(dynlm)
library(corrplot)
library(car)
library(VisCollin)
library(glmnet)
library(strucchange)
library(pls)
library(aTSA)
```

## Importation des données

```{r}
df_path = "Elec_Poland.xlsx"
raw_df = read.xlsx(
  df_path,
  sheet = "Data"
)
```

```{r}
df_T_path = "avg_mean_temp.csv"
df_T_raw = read.csv(df_T_path)
```


## Transformation des données
```{r}
summary(df_T_raw)
```


```{r}
df_T <- df_T_raw %>% 
  rename_at("Category", ~"Year") %>%
  rename_at("Average.Mean.Surface.Air.Temperature...C.", ~"avg_mean_T") %>%
  mutate(ln_avg_mean_T = log(avg_mean_T))
```


```{r}
colnames(raw_df)
```

```{r}
df <- copy(raw_df)
df <- df %>% 
  mutate(C_elec_by_pop = Elec_cons,
  Real_GDP_per_cap = PIB / CPI / Population,
  P_elec = P_elec*10,
  ln_P_elec = log(P_elec),
  Real_Elec_P = P_elec / CPI,
  ln_C_elec_by_pop = log(C_elec_by_pop),
  ln_Real_GDP_per_cap = log(Real_GDP_per_cap),
  ln_Real_Elec_P = log(Real_Elec_P), 
  ln_Year = log(Year),
  lag_ln_C_elec_by_pop = lag(ln_C_elec_by_pop))
df <- df[-nrow(df), ]

summary(df)
```

### Create a dummy
```{r}
df <- df %>% mutate(past_2009 = ifelse(df$Year > 2009, 1, 0),
                    prev_2009 = ifelse(df$Year > 2009, 0, 1)
                    )
```

### Ajout des variable prix scindées

```{r}
df <- df %>% mutate(
  N_ln_P_elec_prev_2009 = ln_P_elec*prev_2009,
  N_ln_Real_Elec_P_past_2009 = ln_Real_Elec_P*past_2009,
  composit_ln_elec_P = N_ln_P_elec_prev_2009 + N_ln_Real_Elec_P_past_2009,
  N_P_elec_prev_2009 = P_elec*prev_2009,
  N_Real_Elec_P_past_2009 = Real_Elec_P*past_2009,
  composit_elec_P = N_P_elec_prev_2009 + N_Real_Elec_P_past_2009
) %>%
  left_join(df_T, by="Year")
```



```{r}
df_diff <- copy(df[-1,])
df_diff$diff_C_elec_by_pop <- diff(df$C_elec_by_pop)
df_diff$diff_Real_GDP_per_cap <- diff(df$Real_GDP_per_cap)
df_diff$diff_Real_Elec_P <- diff(df$Real_Elec_P)

summary(df_diff)
```

## plot data
```{r}
plot(x = df$Year, y= df$C_elec_by_pop)
plot(x = df$Year, y= df$Real_GDP_per_cap)
plot(x = df$Year, y= df$ln_Real_Elec_P)
plot(x = df$Year, y= df$CPI)
plot(x = df_diff$Year, y= df_diff$diff_C_elec_by_pop )
plot(x = df_diff$Year, y= df_diff$diff_Real_GDP_per_cap)
plot(x = df_diff$Year, y= df_diff$diff_Real_Elec_P)
```


## Models

```{r}
model <- lm(
  C_elec_by_pop ~ Real_GDP_per_cap + Real_Elec_P,
  data = df
)

summary(model)

model_ln <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P,
  data = df
)

summary(model_ln)

model_diff <- lm(
  diff_C_elec_by_pop ~ diff_Real_GDP_per_cap + diff_Real_Elec_P,
  data = df_diff
)

summary(model_diff)

model_lag <- lm(
  ln_C_elec_by_pop ~
    lag_ln_C_elec_by_pop +
    ln_Real_GDP_per_cap +
    ln_Real_Elec_P,
  data = df
)

summary(model_lag)

model_trend <- lm(
  ln_C_elec_by_pop ~
    ln_Year +
    ln_Real_GDP_per_cap +
    ln_Real_Elec_P,
  data = df
)

summary(model_trend)
```

Aucun des modèles ne fonctionne particulièrement bien, de plus on observe pas le comportement attendu de la variable prix. En regardant les variation, on observe une rupture de tendance, on teste donc pour la stabilité temporelle.


### Test de stationnarité

```{r}
adf.test(df$ln_C_elec_by_pop)
adf.test(df$ln_Real_GDP_per_cap)
adf.test(df$ln_Real_Elec_P)

```
Askip ça permet de savoir si on ajoute un lag ou une trend mais bon déjà testé et pas ouf.

### Stabilité Temporelle

#### CUSUM
Pour détecter des changement de tendances structurelles sans les connaîtres
```{r}
cusum <- efp(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P ,
  data = df,
  type = "Rec-CUSUM"
)

plot(cusum)
sctest(cusum, type = "CUSUM") 
```
Test de CUSUM ne permet pas de rejeter l'hypothèse de coefficients stables au cours du temps (courbe à l'intérieur des bornes de confiance au seuil de 5%).


####CUSUMQ
Teste la stabilité dans le temps de la variance.
J'ai pas réussi à bien l'implémenter, reprendre le code du prof.

#### Test de Chow
Test s'il y a un changement de coefficient après une date donnée.


```{r}
fs <- Fstats(
ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P,
data = df
)
plot(fs)
sctest(fs)
```
```{r}
0.62*(2023-1990) + 1990
```
On regardant les donnée on va tester pour la rupture sur un petit évantail, on s'attend à ce qu'elle se produise en 2009.

```{r}
chow_result <- sctest(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P, 
  data = df, 
  type = "Chow", 
  point = 18 #2007
)
print("2007")
print(chow_result)

chow_result <- sctest(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P, 
  data = df, 
  type = "Chow", 
  point = 19 #2008
)
print("2008")
print(chow_result)

chow_result <- sctest(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P, 
  data = df, 
  type = "Chow", 
  point = 20 #2009
)
print("2009")
print(chow_result)

chow_result <- sctest(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P, 
  data = df, 
  type = "Chow", 
  point = 21 #2010
)
print("2010")
print(chow_result)

chow_result <- sctest(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P, 
  data = df, 
  type = "Chow", 
  point = 22 #2011
)
print("2011")
print(chow_result)

chow_result <- sctest(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P, 
  data = df, 
  type = "Chow", 
  point = 23 #2012
)
print("2012")
print(chow_result)

chow_result <- sctest(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P, 
  data = df, 
  type = "Chow", 
  point = 24 #2013
)
print("2013")
print(chow_result)
```

Rupture dès 2009 avec une p-value de 0.7%.
(Aussi valable pour 2010 et 2011)

## Structural change


### Models + dummy

```{r}
model <- lm(
  C_elec_by_pop ~ Real_GDP_per_cap + Real_Elec_P + past_2009,
  data = df
)

summary(model)

model_ln <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P + past_2009,
  data = df
)

summary(model_ln)

model_diff <- lm(
  diff_C_elec_by_pop ~ diff_Real_GDP_per_cap + diff_Real_Elec_P + past_2009,
  data = df_diff
)

summary(model_diff)

model_lag <- lm(
  ln_C_elec_by_pop ~
    lag_ln_C_elec_by_pop +
    ln_Real_GDP_per_cap +
    ln_Real_Elec_P +
    past_2009,
  data = df
)

summary(model_lag)

model_trend <- lm(
  ln_C_elec_by_pop ~
    ln_Year +
    ln_Real_GDP_per_cap +
    ln_Real_Elec_P +
    past_2009,
  data = df
)

summary(model_trend)
```
L'influence du prix de l'élec ne fait tj pas sens, sinon la dummy semble bien marcher, reste à la tester dans d'autres conigurations.

### Models * dummy

```{r}
model <- lm(
  C_elec_by_pop ~ Real_GDP_per_cap + Real_Elec_P*past_2009,
  data = df
)

summary(model)

model_ln <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P*past_2009,
  data = df
)

summary(model_ln)

model_diff <- lm(
  diff_C_elec_by_pop ~ diff_Real_GDP_per_cap + diff_Real_Elec_P*past_2009,
  data = df_diff
)

summary(model_diff)

model_lag <- lm(
  ln_C_elec_by_pop ~
    lag_ln_C_elec_by_pop +
    ln_Real_GDP_per_cap +
    ln_Real_Elec_P*past_2009,
  data = df
)

summary(model_lag)

model_trend <- lm(
  ln_C_elec_by_pop ~
    ln_Year +
    ln_Real_GDP_per_cap +
    ln_Real_Elec_P*past_2009,
  data = df
)

summary(model_trend)
```
Le deuxième modèle, loglin est clairement le plus prometteur et commence à donner de l'info. Dans la suis on va se concentrer sur ce dernier.

### Loglin model and dummy

```{r}

model_ln <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P + past_2009,
  data = df
)

summary(model_ln)

model_ln_2 <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P*past_2009,
  data = df
)

summary(model_ln_2)

model_ln_3 <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap*past_2009 + ln_Real_Elec_P,
  data = df
)

summary(model_ln_3)

model_ln_4 <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap*past_2009 + ln_Real_Elec_P*past_2009,
  data = df
)

summary(model_ln_4)

```
Le deuxième modèle semble le meilleur, essayons de le comprendre :
### Best model
####Second Best
```{r}
model <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P*past_2009 ,
  data = df
)

summary(model)
```
Influence positive du revenu OK
Effet fixe de 2009-2010 à prendre en compte avec la modif de l'effet prix.
Effet prix positif avant 2009
Effet prix négatif après 2009
Que s'est-il passé en 2009 ?
En 2008, libéralisation du marché de l'électricité. Pour les industries et les commerces dérégulation dès 2008. Les prix pour les ménages ont continué d'être régulés par l'URE. Projet de déréguler dès 2009 pour les ménages si suffisament de compétition sur le marché (pas le cas). Projet abandonné?

Aussi le prix qu'on a est lequel ? Parce qu'on dirait que ça n'est pas le prix de l'élec pour les ménages mais bien pour les entreprises comme il semble se dérégulé après 2009.

Mon analyse : avant 2009, la régulation des prix rend le signal prix faible : pas de variation rapide des prix donc pas d'optimisation par les entreprises sur le prix de l'électricité. L'impact positif des prix sur la consommation est alors un problème d'endogénéité : si le prix augmente la consommation c'est plutôt parce qu'une hausse de la conso => hausse de la demande => besoin de plus d'offre/inciter à moins consomé => hausse des prix de l'élec par le régulateur (à vérifier dans les rapport comment sont justifiées les hausse si possible)


Après 2009 : dérégulation pour les entreprises donc signal prix plus important et optimisation de la consommation.(explication pas forcément valable à la résolution annuelle). Rupture de l'effet d'endogénéité par l'introduction d'une concurence (endogénéité qui pouvait cammoufler l'effet prix par le passé).


Prix régulé en nominal!!!!!!!!!!!


Ok donc avant 2008 signal prix basé sur le prix réel car régulé pour tous, baisse de la conso en 2009 lié à (crise de 2008, ou dérégulation) puis ça reprend mais là influence des prix réels car dérégulation partielle du marché.

Nouveau modèle X)

####Best
```{r}
best_model <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + composit_ln_elec_P,
  data = df
)

summary(best_model)
```


YES YES YES YES !

```{r}
fs <- Fstats(
ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + composit_ln_elec_P,
data = df
)
plot(fs)
sctest(fs)
```
PLus de rupture !

##Intoduction de la variable de température 

```{r}
model_T <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + composit_ln_elec_P + avg_mean_T,
  data = df
)

summary(model_T)
```
Pas significatif mais dans le bon sens, part faible de chauffage à l'électricité ?

```{r}
model_T_2010 <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + composit_ln_elec_P + avg_mean_T,
  data = filter(df, Year > 2010)
)

summary(model_T_2010)
```
Avec un filtre Year > 2010 significativité à 10%, indique surement un effet d'électrification des chauffage récent, mais pas si important que ça (à interpréter avec les vraies données de chauffage en pologne). J'imagine que la conso d'élec doit être drivé par d'autres facteurs principallement. (Att douteux)


## Analyse des résidus pour le second Best
Une estimastion des moindres carrés ordinaires est non biaisée seulement si les hypothèses sur les résidus sont vérifiées.

### Normalité des résidus

Théorie :
La normalité est nécessaire pour : 
- Des t-tests valides
- Des F-tests valides lorsqu'il y a peu d'échantillons

Tests:
- Graphique: QQ-plot
- Statistique: Shapiro-Wilk / Jarque-Bera

```{r}
res <- residuals(model)

qqnorm(res)
qqline(res, col = "red")

mean(res)
skewness(res)
kurtosis(res)

shapiro.test(res)
```
Le test de Shapiro-Wilk donne une p-value d'environ 98% qui ne permet pas de rejeter l'hypothèse selon laquelle les résidus suivent une distribution normale au seuil de 5%. OK


On peut utiliser les erreurs robustes standards qui corrige la non-normalité et l'hétéroscédasticité (Pas nécessaire mais bonne pratique)

```{r}
coeftest(model, vcov = vcovHC(model, type = "HC1"))
```
(à vérifier mais améliore potentiellement les résul)

### Autocorrélation des résidus
Si il y a de l'autocorrélation des résidus, l'estimation des moindres carrés reste sans biais mais est inefficace et fausse les erreurs standards des coefficients et biaise les tests (t-tests et F-tests) avec des intervalles de confiance trop étroits. Il y a donc un risque de faux-positif (variable faussement considérée comme significative).
```{r}
dwtest(model)
pacf(res)
Box.test(res, lag = 1, type = c("Box-Pierce", "Ljung-Box"), fitdf = 0)
plot(model, which = 1)  # Résidus vs valeurs ajustées, pas d'infos évidentes
```
On peut conserver l'hypothèse delon laquelle l'autocorrélation des résidus est nulle au seuil de 5% (pvalue sur DW 5.5% OUF)


```{r}
acf(residuals(model))
```


### Hétéroscédasticité

Important pour la validité des tests.
Ici on tests si le carré des résidus est lié aux variables explicatives (ou à leurs carrés aussi).
```{r}
bptest(model)
bptest(model, ~ ln_Real_GDP_per_cap + ln_Real_Elec_P + 
         I(ln_Real_GDP_per_cap^2) + I(ln_Real_Elec_P^2),
       data = df)
```
Des p-value qui ne rejette pas l'hypothèse l'homoscédasticité même sous un seuil de 10% ! On est tt bon !

## Multicolinéarité des variables explicatives

### Corrélation
Si on a une forte corrélation entre les varibales explicatives, la variance des estimateurs est accrue.

```{r}
df <- df[-1,]
correlation <- cor(df[, c("ln_Real_GDP_per_cap", "ln_Real_Elec_P", "past_2009")])
corrplot(cor(df[, c("ln_Real_GDP_per_cap", "ln_Real_Elec_P", "past_2009")]))
correlation
```

### VIF

```{r}
vif(model)

vif(model, type = "predictor")
```
Pas de forte colinéarité pour ln_Real_GDP_per_cap et ln_Real_Elec_P (<5).
La collinéarité importante entre les variables d'intéraction fait sens.
En calculant le VIF généralisé, on retrouve en effet que les corrélations sont acceptables.


### Solutions à la multicolinéarité (inutiles dans notre cas)
#### Régression de Ridge

```{r}
# Make sure the model matrix uses the same cleaned data as your y
df_clean <- na.omit(df[, c("ln_C_elec_by_pop", "ln_Real_GDP_per_cap", "ln_Real_Elec_P", "past_2009")])

X <- model.matrix(ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P * past_2009, data = df_clean)[, -1]
y <- df_clean$ln_C_elec_by_pop

# Check dimensions
dim(X)       # should be 33 x p
length(y)    # should be 33

```


```{r}

ridge <- glmnet(X, y, alpha = 0) #alpha = 0 pour ridge (vers 1 c'est lasso)
summary(ridge) 
plot(ridge, xvar = "lambda", label = TRUE)
```
#### Régression en composante principale
```{r}
# Install if needed
# install.packages("pls")
library(pls)

# PCR: regress ln_C_elec_by_pop on predictors
pcr_model <- pcr(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P*past_2009,
  data = df_clean,
  scale = TRUE,   # standardize predictors
  validation = "CV"  # cross-validation to choose # of components
)

# Summary
summary(pcr_model)


# Choose optimal number of components using CV
validationplot(pcr_model, val.type = "MSEP")  # mean squared error

```

## Bootstrap second best 

```{r}
library(boot)

boot_path_elec <- function(data, indices) {
  
  d <- data[indices, ]
  
  fit <- try(
    lm(
      ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P * past_2009,
      data = d
    ),
    silent = TRUE
  )
  
  if (inherits(fit, "try-error"))
    return(rep(NA, nrow(data)))
  
  # Predicted log consumption using ORIGINAL regressors
  ln_hat <- predict(fit, newdata = data)
  
  return(ln_hat)
}


set.seed(123)

boot_res <- boot(
  data = df,
  statistic = boot_path_elec,
  R = 1000
)

boot_mat <- boot_res$t
boot_mat <- boot_mat[complete.cases(boot_mat), ]

fan <- apply(
  boot_mat,
  2,
  quantile,
  probs = c(0.05, 0.5, 0.95)
)

fan <- t(fan)
colnames(fan) <- c("lower", "median", "upper")

fan_level <- exp(fan)
obs_level <- exp(df$ln_C_elec_by_pop)
years <- df$Year

```

```{r}
library(ggplot2)

df_fan <- data.frame(
  year   = years,
  lower  = fan_level[, "lower"],
  median = fan_level[, "median"],
  upper  = fan_level[, "upper"]
)

df_obs <- data.frame(
  year = years,
  obs  = obs_level
)

p_fan <- ggplot() +
  
  # 90% Confidence band
  geom_ribbon(
    data = df_fan,
    aes(x = year, ymin = lower, ymax = upper, fill = "90% CI"),
    alpha = 0.25
  ) +
  
  # Median bootstrap path
  geom_line(
    data = df_fan,
    aes(x = year, y = median, color = "Median bootstrap"),
    linewidth = 1.2
  ) +
  
  # Observed data
  geom_point(
    data = df_obs,
    aes(x = year, y = obs, color = "Observed"),
    size = 2
  ) +
  
  labs(
    title = "Bootstrap Fan Chart: Electricity Consumption per Capita",
    x = "Year",
    y = "Electricity consumption per capita",
    color = "",
    fill  = ""
  ) +
  
  scale_color_manual(
    values = c(
      "Observed" = "black",
      "Median bootstrap" = "#1f78b4"
    )
  ) +
  
  scale_fill_manual(
    values = c("90% CI" = "#1f78b4")
  ) +
  
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "top",
    legend.direction = "horizontal",
    plot.title = element_text(face = "bold"),
    panel.grid.minor = element_blank()
  )

```

```{r}
ggsave(
  filename = "fan_chart_bootstrap_electricity.pdf",
  plot = p_fan,
  width = 8,
  height = 5
)
```

#best_model analysis

```{r}
model <- best_model
```

Une estimastion des moindres carrés ordinaires est non biaisée seulement si les hypothèses sur les résidus sont vérifiées.

### Normalité des résidus

Théorie :
La normalité est nécessaire pour : 
- Des t-tests valides
- Des F-tests valides lorsqu'il y a peu d'échantillons

Tests:
- Graphique: QQ-plot
- Statistique: Shapiro-Wilk / Jarque-Bera

```{r}
res <- residuals(model)

qqnorm(res)
qqline(res, col = "red")

mean(res)
skewness(res)
kurtosis(res)

shapiro.test(res)
```
Le test de Shapiro-Wilk donne une p-value d'environ 58% qui ne permet pas de rejeter l'hypothèse selon laquelle les résidus suivent une distribution normale au seuil de 5%. OK


On peut utiliser les erreurs robustes standards qui corrige la non-normalité et l'hétéroscédasticité (Pas nécessaire mais bonne pratique)

```{r}
coeftest(model, vcov = vcovHC(model, type = "HC1"))
```
(à vérifier mais améliore potentiellement les résul)

### Autocorrélation des résidus
Si il y a de l'autocorrélation des résidus, l'estimation des moindres carrés reste sans biais mais est inefficace et fausse les erreurs standards des coefficients et biaise les tests (t-tests et F-tests) avec des intervalles de confiance trop étroits. Il y a donc un risque de faux-positif (variable faussement considérée comme significative).
```{r}
dwtest(model)
pacf(res)
Box.test(res, lag = 1, type = c("Box-Pierce", "Ljung-Box"), fitdf = 0)
plot(model, which = 1)  # Résidus vs valeurs ajustées, pas d'infos évidentes
```
On rejète l'hypothèse delon laquelle l'autocorrélation des résidus est nulle au seuil de 5% (pvalue sur DW 1.5% NOOOOOOOOOOOOOOOO)


```{r}
acf(residuals(model))
```

Y a grave un lag de 1




##Correction best model

Je n'ai pas ajouté le lag car pas significatif, corrige pas super bien l'autocorré  ET créé de l'hétéroscédasticité.

```{r}
coeftest(model, vcov = NeweyWest(model, lag = 1)) A garder comme ça 
```


### Hétéroscédasticité

Important pour la validité des tests.
Ici on tests si le carré des résidus est lié aux variables explicatives (ou à leurs carrés aussi).
```{r}
bptest(model)
bptest(model, ~ ln_Real_GDP_per_cap + composit_ln_elec_P + 
         I(ln_Real_GDP_per_cap^2) + I(composit_ln_elec_P^2),
       data = df)
```
Des p-value qui ne rejette pas l'hypothèse l'homoscédasticité sous un seuil de 5% ! On est tt bon !

## Multicolinéarité des variables explicatives

### Corrélation
Si on a une forte corrélation entre les varibales explicatives, la variance des estimateurs est accrue.

```{r}
df <- df[-1,]
correlation <- cor(df[, c("ln_Real_GDP_per_cap", "composit_ln_elec_P")])
corrplot(cor(df[, c("ln_Real_GDP_per_cap", "composit_ln_elec_P")]))
correlation
```

### VIF

```{r}
vif(model)

vif(model, type = "predictor")
```
Pas de forte colinéarité pour ln_Real_GDP_per_cap et composit_ln_elec_P (<5).



### Solutions à la multicolinéarité (inutiles dans notre cas)
#### Régression de Ridge

```{r}
# Make sure the model matrix uses the same cleaned data as your y
df_clean <- na.omit(df[, c("ln_C_elec_by_pop", "ln_Real_GDP_per_cap", "composit_ln_elec_P")])

X <- model.matrix(ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + composit_ln_elec_P, data = df_clean)[, -1]
y <- df_clean$ln_C_elec_by_pop

# Check dimensions
dim(X)       # should be 33 x p
length(y)    # should be 33

```


```{r}

ridge <- glmnet(X, y, alpha = 0) #alpha = 0 pour ridge (vers 1 c'est lasso)
summary(ridge) 
plot(ridge, xvar = "lambda", label = TRUE)
```
#### Régression en composante principale
```{r}
# Install if needed
# install.packages("pls")
library(pls)

# PCR: regress ln_C_elec_by_pop on predictors
pcr_model <- pcr(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + composit_ln_elec_P,
  data = df_clean,
  scale = TRUE,   # standardize predictors
  validation = "CV"  # cross-validation to choose # of components
)

# Summary
summary(pcr_model)


# Choose optimal number of components using CV
validationplot(pcr_model, val.type = "MSEP")  # mean squared error

```

## Bootstrap best 

```{r}
library(boot)

boot_path_elec <- function(data, indices) {
  
  d <- data[indices, ]
  
  fit <- try(
    lm(
      ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + composit_ln_elec_P,
      data = d
    ),
    silent = TRUE
  )
  
  if (inherits(fit, "try-error"))
    return(rep(NA, nrow(data)))
  
  # Predicted log consumption using ORIGINAL regressors
  ln_hat <- predict(fit, newdata = data)
  
  return(ln_hat)
}


set.seed(123)

boot_res <- boot(
  data = df,
  statistic = boot_path_elec,
  R = 1000
)

boot_mat <- boot_res$t
boot_mat <- boot_mat[complete.cases(boot_mat), ]

fan <- apply(
  boot_mat,
  2,
  quantile,
  probs = c(0.05, 0.5, 0.95)
)

fan <- t(fan)
colnames(fan) <- c("lower", "median", "upper")

fan_level <- exp(fan)
obs_level <- exp(df$ln_C_elec_by_pop)
years <- df$Year

```

```{r}
library(ggplot2)

df_fan <- data.frame(
  year   = years,
  lower  = fan_level[, "lower"],
  median = fan_level[, "median"],
  upper  = fan_level[, "upper"]
)

df_obs <- data.frame(
  year = years,
  obs  = obs_level
)

p_fan <- ggplot() +
  
  # 90% Confidence band
  geom_ribbon(
    data = df_fan,
    aes(x = year, ymin = lower, ymax = upper, fill = "90% CI"),
    alpha = 0.25
  ) +
  
  # Median bootstrap path
  geom_line(
    data = df_fan,
    aes(x = year, y = median, color = "Median bootstrap"),
    linewidth = 1.2
  ) +
  
  # Observed data
  geom_point(
    data = df_obs,
    aes(x = year, y = obs, color = "Observed"),
    size = 2
  ) +
  
  labs(
    title = "Bootstrap Fan Chart: Electricity Consumption per Capita",
    x = "Year",
    y = "Electricity consumption per capita",
    color = "",
    fill  = ""
  ) +
  
  scale_color_manual(
    values = c(
      "Observed" = "black",
      "Median bootstrap" = "#1f78b4"
    )
  ) +
  
  scale_fill_manual(
    values = c("90% CI" = "#1f78b4")
  ) +
  
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "top",
    legend.direction = "horizontal",
    plot.title = element_text(face = "bold"),
    panel.grid.minor = element_blank()
  )

```

```{r}
ggsave(
  filename = "fan_chart_bootstrap_electricity_best.pdf",
  plot = p_fan,
  width = 8,
  height = 5
)
```


## To do electric model
```{r}

```


