---
title: "model_conso_elec_poland"
output:
  pdf_document: default
  html_document: default
date: "2026-01-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# To do : 

ajout de variable : indice de temp

Model prix elec réel <- prix_elec_passé + prop ENR + régulation type ETS ?

# Modèle de la consomation d'électricité en Pologne

## Libraires
```{r}
library(openxlsx)
library(tidyverse)
library(data.table)   
library(e1071)
library(lmtest)
library(sandwich)
library(nlme)
library(dynlm)
library(corrplot)
library(car)
library(VisCollin)
library(glmnet)
library(strucchange)
library(pls)
library(aTSA)
library(data.table)

```

## Importation des données

```{r}
df_path = "Elec_Poland.xlsx"
raw_df = read.xlsx(
  df_path,
  sheet = "Data"
)
```

```{r}
df_T_path = "avg_mean_temp.csv"
df_T_raw = read.csv(df_T_path)
```


## Transformation des données
```{r}
summary(df_T_raw)
```


```{r}
df_T <- df_T_raw %>% 
  rename_at("Category", ~"Year") %>%
  rename_at("Average.Mean.Surface.Air.Temperature...C.", ~"avg_mean_T") %>%
  mutate(ln_avg_mean_T = log(avg_mean_T))
```


```{r}
colnames(raw_df)
```

```{r}
df <- copy(raw_df)
df <- df %>% 
  mutate(C_elec_by_pop = Elec_cons,
  Real_GDP_per_cap = PIB / CPI / Population,
  P_elec = P_elec*10,
  ln_P_elec = log(P_elec),
  Real_Elec_P = P_elec / CPI,
  ln_C_elec_by_pop = log(C_elec_by_pop),
  ln_Real_GDP_per_cap = log(Real_GDP_per_cap),
  ln_Real_Elec_P = log(Real_Elec_P), 
  ln_Year = log(Year),
  lag_ln_C_elec_by_pop = lag(ln_C_elec_by_pop))
df <- df[-nrow(df), ]


summary(df)
```

### Create a dummy
```{r}
df <- df %>% mutate(past_2009 = ifelse(df$Year > 2009, 1, 0),
                    prev_2009 = ifelse(df$Year > 2009, 0, 1)
                    )
```

### Ajout des variable prix scindées

```{r}
df <- df %>% mutate(
  N_ln_P_elec_prev_2009 = ln_P_elec*prev_2009,
  N_ln_Real_Elec_P_past_2009 = ln_Real_Elec_P*past_2009,
  composit_ln_elec_P = N_ln_P_elec_prev_2009 + N_ln_Real_Elec_P_past_2009,
  N_P_elec_prev_2009 = P_elec*prev_2009,
  N_Real_Elec_P_past_2009 = Real_Elec_P*past_2009,
  composit_elec_P = N_P_elec_prev_2009 + N_Real_Elec_P_past_2009
) %>%
  left_join(df_T, by="Year")
```



```{r}
df_diff <- copy(df[-1,])
df_diff$diff_C_elec_by_pop <- diff(df$C_elec_by_pop)
df_diff$diff_Real_GDP_per_cap <- diff(df$Real_GDP_per_cap)
df_diff$diff_Real_Elec_P <- diff(df$Real_Elec_P)

summary(df_diff)
```

## plot data
```{r}
plot(x = df$Year, y= df$C_elec_by_pop)
plot(x = df$Year, y= df$Real_GDP_per_cap)
plot(x = df$Year, y= df$ln_Real_Elec_P)
plot(x = df$Year, y= df$CPI)
plot(x = df_diff$Year, y= df_diff$diff_C_elec_by_pop )
plot(x = df_diff$Year, y= df_diff$diff_Real_GDP_per_cap)
plot(x = df_diff$Year, y= df_diff$diff_Real_Elec_P)
```


## Models

```{r}
model <- lm(
  C_elec_by_pop ~ Real_GDP_per_cap + Real_Elec_P,
  data = df
)

summary(model)

model_ln <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P,
  data = df
)

summary(model_ln)

model_diff <- lm(
  diff_C_elec_by_pop ~ diff_Real_GDP_per_cap + diff_Real_Elec_P,
  data = df_diff
)

summary(model_diff)

model_lag <- lm(
  ln_C_elec_by_pop ~
    lag_ln_C_elec_by_pop +
    ln_Real_GDP_per_cap +
    ln_Real_Elec_P,
  data = df
)

summary(model_lag)

model_trend <- lm(
  ln_C_elec_by_pop ~
    ln_Year +
    ln_Real_GDP_per_cap +
    ln_Real_Elec_P,
  data = df
)

summary(model_trend)
```

Aucun des modèles ne fonctionne particulièrement bien, de plus on observe pas le comportement attendu de la variable prix. En regardant les variation, on observe une rupture de tendance, on teste donc pour la stabilité temporelle.


### Test de stationnarité

```{r}
adf.test(df$ln_C_elec_by_pop)
adf.test(df$ln_Real_GDP_per_cap)
adf.test(df$ln_Real_Elec_P)

```
Askip ça permet de savoir si on ajoute un lag ou une trend mais bon déjà testé et pas ouf.

### Stabilité Temporelle

#### CUSUM
Pour détecter des changement de tendances structurelles sans les connaîtres
```{r}
cusum <- efp(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P ,
  data = df,
  type = "Rec-CUSUM"
)

plot(cusum)
sctest(cusum, type = "CUSUM") 
```
Test de CUSUM ne permet pas de rejeter l'hypothèse de coefficients stables au cours du temps (courbe à l'intérieur des bornes de confiance au seuil de 5%).


####CUSUMQ
Teste la stabilité dans le temps de la variance.
J'ai pas réussi à bien l'implémenter, reprendre le code du prof.

#### Test de Chow
Test s'il y a un changement de coefficient après une date donnée.


```{r}
fs <- Fstats(
ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P,
data = df
)
plot(fs)
sctest(fs)
```
```{r}
0.62*(2023-1990) + 1990
```
On regardant les donnée on va tester pour la rupture sur un petit évantail, on s'attend à ce qu'elle se produise en 2009.

```{r}
chow_result <- sctest(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P, 
  data = df, 
  type = "Chow", 
  point = 18 #2007
)
print("2007")
print(chow_result)

chow_result <- sctest(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P, 
  data = df, 
  type = "Chow", 
  point = 19 #2008
)
print("2008")
print(chow_result)

chow_result <- sctest(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P, 
  data = df, 
  type = "Chow", 
  point = 20 #2009
)
print("2009")
print(chow_result)

chow_result <- sctest(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P, 
  data = df, 
  type = "Chow", 
  point = 21 #2010
)
print("2010")
print(chow_result)

chow_result <- sctest(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P, 
  data = df, 
  type = "Chow", 
  point = 22 #2011
)
print("2011")
print(chow_result)

chow_result <- sctest(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P, 
  data = df, 
  type = "Chow", 
  point = 23 #2012
)
print("2012")
print(chow_result)

chow_result <- sctest(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P, 
  data = df, 
  type = "Chow", 
  point = 24 #2013
)
print("2013")
print(chow_result)
```

Rupture dès 2009 avec une p-value de 0.7%.
(Aussi valable pour 2010 et 2011)

## Structural change


### Models + dummy

```{r}
model <- lm(
  C_elec_by_pop ~ Real_GDP_per_cap + Real_Elec_P + past_2009,
  data = df
)

summary(model)

model_ln <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P + past_2009,
  data = df
)

summary(model_ln)

model_diff <- lm(
  diff_C_elec_by_pop ~ diff_Real_GDP_per_cap + diff_Real_Elec_P + past_2009,
  data = df_diff
)

summary(model_diff)

model_lag <- lm(
  ln_C_elec_by_pop ~
    lag_ln_C_elec_by_pop +
    ln_Real_GDP_per_cap +
    ln_Real_Elec_P +
    past_2009,
  data = df
)

summary(model_lag)

model_trend <- lm(
  ln_C_elec_by_pop ~
    ln_Year +
    ln_Real_GDP_per_cap +
    ln_Real_Elec_P +
    past_2009,
  data = df
)

summary(model_trend)
```
L'influence du prix de l'élec ne fait tj pas sens, sinon la dummy semble bien marcher, reste à la tester dans d'autres conigurations.

### Models * dummy

```{r}
model <- lm(
  C_elec_by_pop ~ Real_GDP_per_cap + Real_Elec_P*past_2009,
  data = df
)

summary(model)

model_ln <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P*past_2009,
  data = df
)

summary(model_ln)

model_diff <- lm(
  diff_C_elec_by_pop ~ diff_Real_GDP_per_cap + diff_Real_Elec_P*past_2009,
  data = df_diff
)

summary(model_diff)

model_lag <- lm(
  ln_C_elec_by_pop ~
    lag_ln_C_elec_by_pop +
    ln_Real_GDP_per_cap +
    ln_Real_Elec_P*past_2009,
  data = df
)

summary(model_lag)

model_trend <- lm(
  ln_C_elec_by_pop ~
    ln_Year +
    ln_Real_GDP_per_cap +
    ln_Real_Elec_P*past_2009,
  data = df
)

summary(model_trend)
```
Le deuxième modèle, loglin est clairement le plus prometteur et commence à donner de l'info. Dans la suis on va se concentrer sur ce dernier.

### Loglin model and dummy

```{r}

model_ln <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P + past_2009,
  data = df
)

summary(model_ln)

model_ln_2 <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P*past_2009,
  data = df
)

summary(model_ln_2)

model_ln_3 <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap*past_2009 + ln_Real_Elec_P,
  data = df
)

summary(model_ln_3)

model_ln_4 <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap*past_2009 + ln_Real_Elec_P*past_2009,
  data = df
)

summary(model_ln_4)

```
Le deuxième modèle semble le meilleur, essayons de le comprendre :
### Best models
####Second Best
```{r}
model <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P*past_2009 ,
  data = df
)

summary(model)
```
Influence positive du revenu OK
Effet fixe de 2009-2010 à prendre en compte avec la modif de l'effet prix.
Effet prix positif avant 2009
Effet prix négatif après 2009
Que s'est-il passé en 2009 ?
En 2008, libéralisation du marché de l'électricité. Pour les industries et les commerces dérégulation dès 2008. Les prix pour les ménages ont continué d'être régulés par l'URE. Projet de déréguler dès 2009 pour les ménages si suffisament de compétition sur le marché (pas le cas). Projet abandonné?

Aussi le prix qu'on a est lequel ? Parce qu'on dirait que ça n'est pas le prix de l'élec pour les ménages mais bien pour les entreprises comme il semble se dérégulé après 2009.

Mon analyse : avant 2009, la régulation des prix rend le signal prix faible : pas de variation rapide des prix donc pas d'optimisation par les entreprises sur le prix de l'électricité. L'impact positif des prix sur la consommation est alors un problème d'endogénéité : si le prix augmente la consommation c'est plutôt parce qu'une hausse de la conso => hausse de la demande => besoin de plus d'offre/inciter à moins consomé => hausse des prix de l'élec par le régulateur (à vérifier dans les rapport comment sont justifiées les hausse si possible)


Après 2009 : dérégulation pour les entreprises donc signal prix plus important et optimisation de la consommation.(explication pas forcément valable à la résolution annuelle). Rupture de l'effet d'endogénéité par l'introduction d'une concurence (endogénéité qui pouvait cammoufler l'effet prix par le passé).


Prix régulé en nominal!!!!!!!!!!!


Ok donc avant 2008 signal prix basé sur le prix réel car régulé pour tous, baisse de la conso en 2009 lié à (crise de 2008, ou dérégulation) puis ça reprend mais là influence des prix réels car dérégulation partielle du marché.

Nouveau modèle X)

####Best
```{r}
best_model <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + composit_ln_elec_P,
  data = df
)

summary(best_model)
```


YES YES YES YES !

```{r}
fs <- Fstats(
ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + composit_ln_elec_P,
data = df
)
plot(fs)
sctest(fs)
```
PLus de rupture !

##Intoduction de la variable de température 

```{r}
model_T <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + composit_ln_elec_P + avg_mean_T,
  data = df
)

summary(model_T)
```
Pas significatif mais dans le bon sens, part faible de chauffage à l'électricité ?

```{r}
model_T_2010 <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + composit_ln_elec_P + avg_mean_T,
  data = filter(df, Year > 2010)
)

summary(model_T_2010)
```
Avec un filtre Year > 2010 significativité à 10%, indique surement un effet d'électrification des chauffage récent, mais pas si important que ça (à interpréter avec les vraies données de chauffage en pologne). J'imagine que la conso d'élec doit être drivé par d'autres facteurs principallement. (Att douteux)


## Analyse des résidus pour le second Best
Une estimastion des moindres carrés ordinaires est non biaisée seulement si les hypothèses sur les résidus sont vérifiées.

### Normalité des résidus

Théorie :
La normalité est nécessaire pour : 
- Des t-tests valides
- Des F-tests valides lorsqu'il y a peu d'échantillons

Tests:
- Graphique: QQ-plot
- Statistique: Shapiro-Wilk / Jarque-Bera

```{r}
res <- residuals(model)

qqnorm(res)
qqline(res, col = "red")

mean(res)
skewness(res)
kurtosis(res)

shapiro.test(res)
```
Le test de Shapiro-Wilk donne une p-value d'environ 98% qui ne permet pas de rejeter l'hypothèse selon laquelle les résidus suivent une distribution normale au seuil de 5%. OK


On peut utiliser les erreurs robustes standards qui corrige la non-normalité et l'hétéroscédasticité (Pas nécessaire mais bonne pratique)

```{r}
coeftest(model, vcov = vcovHC(model, type = "HC1"))
```
(à vérifier mais améliore potentiellement les résul)

### Autocorrélation des résidus
Si il y a de l'autocorrélation des résidus, l'estimation des moindres carrés reste sans biais mais est inefficace et fausse les erreurs standards des coefficients et biaise les tests (t-tests et F-tests) avec des intervalles de confiance trop étroits. Il y a donc un risque de faux-positif (variable faussement considérée comme significative).
```{r}
dwtest(model)
pacf(res)
Box.test(res, lag = 1, type = c("Box-Pierce", "Ljung-Box"), fitdf = 0)
plot(model, which = 1)  # Résidus vs valeurs ajustées, pas d'infos évidentes
```
On peut conserver l'hypothèse delon laquelle l'autocorrélation des résidus est nulle au seuil de 5% (pvalue sur DW 5.5% OUF)


```{r}
acf(residuals(model))
```


### Hétéroscédasticité

Important pour la validité des tests.
Ici on tests si le carré des résidus est lié aux variables explicatives (ou à leurs carrés aussi).
```{r}
bptest(model)
bptest(model, ~ ln_Real_GDP_per_cap + ln_Real_Elec_P + 
         I(ln_Real_GDP_per_cap^2) + I(ln_Real_Elec_P^2),
       data = df)
```
Des p-value qui ne rejette pas l'hypothèse l'homoscédasticité même sous un seuil de 10% ! On est tt bon !

## Multicolinéarité des variables explicatives

### Corrélation
Si on a une forte corrélation entre les varibales explicatives, la variance des estimateurs est accrue.

```{r}
df <- df[-1,]
correlation <- cor(df[, c("ln_Real_GDP_per_cap", "ln_Real_Elec_P", "past_2009")])
corrplot(cor(df[, c("ln_Real_GDP_per_cap", "ln_Real_Elec_P", "past_2009")]))
correlation
```

### VIF

```{r}
vif(model)

vif(model, type = "predictor")
```
Pas de forte colinéarité pour ln_Real_GDP_per_cap et ln_Real_Elec_P (<5).
La collinéarité importante entre les variables d'intéraction fait sens.
En calculant le VIF généralisé, on retrouve en effet que les corrélations sont acceptables.


### Solutions à la multicolinéarité (inutiles dans notre cas)
#### Régression de Ridge

```{r}
# Make sure the model matrix uses the same cleaned data as your y
df_clean <- na.omit(df[, c("ln_C_elec_by_pop", "ln_Real_GDP_per_cap", "ln_Real_Elec_P", "past_2009")])

X <- model.matrix(ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P * past_2009, data = df_clean)[, -1]
y <- df_clean$ln_C_elec_by_pop

# Check dimensions
dim(X)       # should be 33 x p
length(y)    # should be 33

```


```{r}

ridge <- glmnet(X, y, alpha = 0) #alpha = 0 pour ridge (vers 1 c'est lasso)
summary(ridge) 
plot(ridge, xvar = "lambda", label = TRUE)
```
#### Régression en composante principale
```{r}
# Install if needed
# install.packages("pls")
library(pls)

# PCR: regress ln_C_elec_by_pop on predictors
pcr_model <- pcr(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P*past_2009,
  data = df_clean,
  scale = TRUE,   # standardize predictors
  validation = "CV"  # cross-validation to choose # of components
)

# Summary
summary(pcr_model)


# Choose optimal number of components using CV
validationplot(pcr_model, val.type = "MSEP")  # mean squared error

```

## Bootstrap second best 

```{r}
library(boot)

boot_path_elec <- function(data, indices) {
  
  d <- data[indices, ]
  
  fit <- try(
    lm(
      ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P * past_2009,
      data = d
    ),
    silent = TRUE
  )
  
  if (inherits(fit, "try-error"))
    return(rep(NA, nrow(data)))
  
  # Predicted log consumption using ORIGINAL regressors
  ln_hat <- predict(fit, newdata = data)
  
  return(ln_hat)
}


set.seed(123)

boot_res <- boot(
  data = df,
  statistic = boot_path_elec,
  R = 1000
)

boot_mat <- boot_res$t
boot_mat <- boot_mat[complete.cases(boot_mat), ]

fan <- apply(
  boot_mat,
  2,
  quantile,
  probs = c(0.05, 0.5, 0.95)
)

fan <- t(fan)
colnames(fan) <- c("lower", "median", "upper")

fan_level <- exp(fan)
obs_level <- exp(df$ln_C_elec_by_pop)
years <- df$Year

```

```{r}
library(ggplot2)

df_fan <- data.frame(
  year   = years,
  lower  = fan_level[, "lower"],
  median = fan_level[, "median"],
  upper  = fan_level[, "upper"]
)

df_obs <- data.frame(
  year = years,
  obs  = obs_level
)

p_fan <- ggplot() +
  
  # 90% Confidence band
  geom_ribbon(
    data = df_fan,
    aes(x = year, ymin = lower, ymax = upper, fill = "90% CI"),
    alpha = 0.25
  ) +
  
  # Median bootstrap path
  geom_line(
    data = df_fan,
    aes(x = year, y = median, color = "Median bootstrap"),
    linewidth = 1.2
  ) +
  
  # Observed data
  geom_point(
    data = df_obs,
    aes(x = year, y = obs, color = "Observed"),
    size = 2
  ) +
  
  labs(
    title = "Bootstrap Fan Chart: Electricity Consumption per Capita",
    x = "Year",
    y = "Electricity consumption per capita",
    color = "",
    fill  = ""
  ) +
  
  scale_color_manual(
    values = c(
      "Observed" = "black",
      "Median bootstrap" = "#1f78b4"
    )
  ) +
  
  scale_fill_manual(
    values = c("90% CI" = "#1f78b4")
  ) +
  
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "top",
    legend.direction = "horizontal",
    plot.title = element_text(face = "bold"),
    panel.grid.minor = element_blank()
  )

```

```{r}
ggsave(
  filename = "fan_chart_bootstrap_electricity.pdf",
  plot = p_fan,
  width = 8,
  height = 5
)
```

#best_model analysis

```{r}
model <- best_model
```

Une estimastion des moindres carrés ordinaires est non biaisée seulement si les hypothèses sur les résidus sont vérifiées.

### Normalité des résidus

Théorie :
La normalité est nécessaire pour : 
- Des t-tests valides
- Des F-tests valides lorsqu'il y a peu d'échantillons

Tests:
- Graphique: QQ-plot
- Statistique: Shapiro-Wilk / Jarque-Bera

```{r}
res <- residuals(model)

qqnorm(res)
qqline(res, col = "red")

mean(res)
skewness(res)
kurtosis(res)

shapiro.test(res)
```
Le test de Shapiro-Wilk donne une p-value d'environ 58% qui ne permet pas de rejeter l'hypothèse selon laquelle les résidus suivent une distribution normale au seuil de 5%. OK


On peut utiliser les erreurs robustes standards qui corrige la non-normalité et l'hétéroscédasticité (Pas nécessaire mais bonne pratique)

```{r}
coeftest(model, vcov = vcovHC(model, type = "HC1"))
```
(à vérifier mais améliore potentiellement les résul)

### Autocorrélation des résidus
Si il y a de l'autocorrélation des résidus, l'estimation des moindres carrés reste sans biais mais est inefficace et fausse les erreurs standards des coefficients et biaise les tests (t-tests et F-tests) avec des intervalles de confiance trop étroits. Il y a donc un risque de faux-positif (variable faussement considérée comme significative).
```{r}
dwtest(model)
pacf(res)
Box.test(res, lag = 1, type = c("Box-Pierce", "Ljung-Box"), fitdf = 0)
plot(model, which = 1)  # Résidus vs valeurs ajustées, pas d'infos évidentes
```
On rejète l'hypothèse delon laquelle l'autocorrélation des résidus est nulle au seuil de 5% (pvalue sur DW 1.5% NOOOOOOOOOOOOOOOO)


```{r}
acf(residuals(model))
```

Y a grave un lag de 1




##Correction best model

Je n'ai pas ajouté le lag car pas significatif, corrige pas super bien l'autocorré  ET créé de l'hétéroscédasticité.

```{r}
coeftest(model, vcov = NeweyWest(model, lag = 1)) A garder comme ça 
```


### Hétéroscédasticité

Important pour la validité des tests.
Ici on tests si le carré des résidus est lié aux variables explicatives (ou à leurs carrés aussi).
```{r}
bptest(model)
bptest(model, ~ ln_Real_GDP_per_cap + composit_ln_elec_P + 
         I(ln_Real_GDP_per_cap^2) + I(composit_ln_elec_P^2),
       data = df)
```
Des p-value qui ne rejette pas l'hypothèse l'homoscédasticité sous un seuil de 5% ! On est tt bon !

## Multicolinéarité des variables explicatives

### Corrélation
Si on a une forte corrélation entre les varibales explicatives, la variance des estimateurs est accrue.

```{r}
df <- df[-1,]
correlation <- cor(df[, c("ln_Real_GDP_per_cap", "composit_ln_elec_P")])
corrplot(cor(df[, c("ln_Real_GDP_per_cap", "composit_ln_elec_P")]))
correlation
```

### VIF

```{r}
vif(model)

vif(model, type = "predictor")
```
Pas de forte colinéarité pour ln_Real_GDP_per_cap et composit_ln_elec_P (<5).



### Solutions à la multicolinéarité (inutiles dans notre cas)
#### Régression de Ridge

```{r}
# Make sure the model matrix uses the same cleaned data as your y
df_clean <- na.omit(df[, c("ln_C_elec_by_pop", "ln_Real_GDP_per_cap", "composit_ln_elec_P")])

X <- model.matrix(ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + composit_ln_elec_P, data = df_clean)[, -1]
y <- df_clean$ln_C_elec_by_pop

# Check dimensions
dim(X)       # should be 33 x p
length(y)    # should be 33

```


```{r}

ridge <- glmnet(X, y, alpha = 0) #alpha = 0 pour ridge (vers 1 c'est lasso)
summary(ridge) 
plot(ridge, xvar = "lambda", label = TRUE)
```
#### Régression en composante principale
```{r}
# Install if needed
# install.packages("pls")
library(pls)

# PCR: regress ln_C_elec_by_pop on predictors
pcr_model <- pcr(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + composit_ln_elec_P,
  data = df_clean,
  scale = TRUE,   # standardize predictors
  validation = "CV"  # cross-validation to choose # of components
)

# Summary
summary(pcr_model)


# Choose optimal number of components using CV
validationplot(pcr_model, val.type = "MSEP")  # mean squared error

```

## Bootstrap best 

```{r}
library(boot)

boot_path_elec <- function(data, indices) {
  
  d <- data[indices, ]
  
  fit <- try(
    lm(
      ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + composit_ln_elec_P,
      data = d
    ),
    silent = TRUE
  )
  
  if (inherits(fit, "try-error"))
    return(rep(NA, nrow(data)))
  
  # Predicted log consumption using ORIGINAL regressors
  ln_hat <- predict(fit, newdata = data)
  
  return(ln_hat)
}


set.seed(123)

boot_res <- boot(
  data = df,
  statistic = boot_path_elec,
  R = 1000
)

boot_mat <- boot_res$t
boot_mat <- boot_mat[complete.cases(boot_mat), ]

fan <- apply(
  boot_mat,
  2,
  quantile,
  probs = c(0.05, 0.5, 0.95)
)

fan <- t(fan)
colnames(fan) <- c("lower", "median", "upper")

fan_level <- exp(fan)
obs_level <- exp(df$ln_C_elec_by_pop)
years <- df$Year

```

```{r}
library(ggplot2)

df_fan <- data.frame(
  year   = years,
  lower  = fan_level[, "lower"],
  median = fan_level[, "median"],
  upper  = fan_level[, "upper"]
)

df_obs <- data.frame(
  year = years,
  obs  = obs_level
)

p_fan <- ggplot() +
  
  # 90% Confidence band
  geom_ribbon(
    data = df_fan,
    aes(x = year, ymin = lower, ymax = upper, fill = "90% CI"),
    alpha = 0.25
  ) +
  
  # Median bootstrap path
  geom_line(
    data = df_fan,
    aes(x = year, y = median, color = "Median bootstrap"),
    linewidth = 1.2
  ) +
  
  # Observed data
  geom_point(
    data = df_obs,
    aes(x = year, y = obs, color = "Observed"),
    size = 2
  ) +
  
  labs(
    title = "Bootstrap Fan Chart: Electricity Consumption per Capita",
    x = "Year",
    y = "Electricity consumption per capita",
    color = "",
    fill  = ""
  ) +
  
  scale_color_manual(
    values = c(
      "Observed" = "black",
      "Median bootstrap" = "#1f78b4"
    )
  ) +
  
  scale_fill_manual(
    values = c("90% CI" = "#1f78b4")
  ) +
  
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "top",
    legend.direction = "horizontal",
    plot.title = element_text(face = "bold"),
    panel.grid.minor = element_blank()
  )

```

```{r}
ggsave(
  filename = "fan_chart_bootstrap_electricity_best.pdf",
  plot = p_fan,
  width = 8,
  height = 5
)
```


# electric price model
## Imports
```{r}
library(readxl)
df_energy_path = "WorldEnergyBalancesHighlights2025.xlsx"
df_energy_raw <- read_excel(df_energy_path, sheet="TimeSeries_1971-2024", skip=1)
```

## Transform

```{r}
df_energy <- df_energy_raw %>% 
  filter(Country == "Poland") %>%
  filter(Flow == "Total energy supply (PJ)") %>%
  filter(Product =="Renewables and waste" | Product =="Total") %>%
  select(-c("Country", "Flow", "NoCountry", "NoFlow", "NoProduct"))

df_energy <- rbind(colnames(df_energy), df_energy) %>%
  transpose()

colnames(df_energy) <- as.character(df_energy[1, ])
df_energy <- df_energy[-1,]
rownames(df_energy) <- NULL
df_energy <- rename_at(df_energy, "Product", ~"Year")
df_energy <- rename_at(df_energy, "Renewables and waste", ~"Renewables_and_waste")
df_energy <- df_energy %>%
  mutate_all(as.numeric) %>%
  mutate(REshare = Renewables_and_waste / Total)

summary(df_energy)

```

```{r}
df_full <- df %>%
  left_join(df_energy, by = "Year") %>%
  mutate(lag_composit_ln_elec_P = lag(composit_ln_elec_P))
```

## First elec price models

```{r}
model_P_1 <- lm(
  composit_ln_elec_P ~ REshare ,
  data = filter(df_full, Year > 2009)
)

summary(model_P_1)

model_P_2 <- lm(
  composit_ln_elec_P ~ REshare + lag_composit_ln_elec_P,
  data = filter(df_full, Year > 2010)
)

summary(model_P_2)

model <- model_P_1

```
### Normalité des résidus

Théorie :
La normalité est nécessaire pour : 
- Des t-tests valides
- Des F-tests valides lorsqu'il y a peu d'échantillons

Tests:
- Graphique: QQ-plot
- Statistique: Shapiro-Wilk / Jarque-Bera

```{r}
res <- residuals(model)

qqnorm(res)
qqline(res, col = "red")

mean(res)
skewness(res)
kurtosis(res)

shapiro.test(res)
```
Le test de Shapiro-Wilk donne une p-value d'environ 4.8% qui ne permet pas de conserver l'hypothèse selon laquelle les résidus suivent une distribution normale au seuil de 5%. OK


On peut utiliser les erreurs robustes standards qui corrige la non-normalité et l'hétéroscédasticité (Pas nécessaire mais bonne pratique)

```{r}
coeftest(model, vcov = vcovHC(model, type = "HC1"))
```
(à vérifier mais améliore potentiellement les résultats)

### Autocorrélation des résidus
Si il y a de l'autocorrélation des résidus, l'estimation des moindres carrés reste sans biais mais est inefficace et fausse les erreurs standards des coefficients et biaise les tests (t-tests et F-tests) avec des intervalles de confiance trop étroits. Il y a donc un risque de faux-positif (variable faussement considérée comme significative).
```{r}
dwtest(model)
pacf(res)
Box.test(res, lag = 1, type = c("Box-Pierce", "Ljung-Box"), fitdf = 0)
plot(model, which = 1)  # Résidus vs valeurs ajustées, pas d'infos évidentes
```
On conserve l'hypothèse delon laquelle l'autocorrélation des résidus est nulle au seuil de 5% (pvalue sur DW 23%)


### Hétéroscédasticité

Important pour la validité des tests.
Ici on tests si le carré des résidus est lié aux variables explicatives (ou à leurs carrés aussi).
```{r}
bptest(model)
bptest(model, ~ ln_Real_GDP_per_cap + composit_ln_elec_P + 
         I(ln_Real_GDP_per_cap^2) + I(composit_ln_elec_P^2),
       data = df)
```
Des p-value qui ne rejette pas l'hypothèse l'homoscédasticité sous un seuil de 5% ! On est tt bon !

Pas besoin de tester pour multicolinéarité puisqu'une seule variable

### Bootstrap élec price model

```{r}
library(boot)
library(dplyr)

df_model <- df_full %>% 
  filter(Year > 2009)

boot_path_P1 <- function(data, indices) {
  
  d <- data[indices, ]
  
  fit <- try(
    lm(
      composit_ln_elec_P ~ REshare,
      data = d
    ),
    silent = TRUE
  )
  
  if (inherits(fit, "try-error"))
    return(rep(NA, nrow(data)))
  
  # Predicted log price using ORIGINAL regressors
  ln_hat <- predict(fit, newdata = data)
  
  return(ln_hat)
}

set.seed(123)

boot_res <- boot(
  data = df_model,
  statistic = boot_path_P1,
  R = 1000
)

boot_mat <- boot_res$t
boot_mat <- boot_mat[complete.cases(boot_mat), ]

fan <- apply(
  boot_mat,
  2,
  quantile,
  probs = c(0.05, 0.5, 0.95)
)

fan <- t(fan)
colnames(fan) <- c("lower", "median", "upper")

fan_level <- exp(fan)
obs_level <- exp(df_model$composit_ln_elec_P)
years <- df_model$Year

```

```{r}

df_fan <- data.frame(
  year   = years,
  lower  = fan_level[, "lower"],
  median = fan_level[, "median"],
  upper  = fan_level[, "upper"]
)

df_obs <- data.frame(
  year = years,
  obs  = obs_level
)

p_fan <- ggplot() +
  
  geom_ribbon(
    data = df_fan,
    aes(x = year, ymin = lower, ymax = upper, fill = "90% CI"),
    alpha = 0.25
  ) +
  
  geom_line(
    data = df_fan,
    aes(x = year, y = median, color = "Median bootstrap"),
    linewidth = 1.2
  ) +
  
  geom_point(
    data = df_obs,
    aes(x = year, y = obs, color = "Observed"),
    size = 2
  ) +
  
  labs(
    title = "Bootstrap Fan Chart: Electricity Price Index",
    x = "Year",
    y = "Electricity price index (level)",
    color = "",
    fill  = ""
  ) +
  
  scale_color_manual(
    values = c(
      "Observed" = "black",
      "Median bootstrap" = "#1f78b4"
    )
  ) +
  
  scale_fill_manual(
    values = c("90% CI" = "#1f78b4")
  ) +
  
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "top",
    legend.direction = "horizontal",
    plot.title = element_text(face = "bold"),
    panel.grid.minor = element_blank()
  )

```

```{r}
ggsave(
  filename = "fan_chart_bootstrap_price_REshare.pdf",
  plot = p_fan,
  width = 8,
  height = 5
)

```



## Combined bootstrap
### Trajectory

https://www.oecd.org/fr/publications/perspectives-economiques-de-l-ocde-volume-2025-numero-2_62298503-fr/full-report/poland_eefa15ca.html#indicator-d1e9631-5f6bcac8ee on arrondit à 3% de croissance jusqu'à 2030
+ doc de la commission, on monte à 30% d'ER en 2030 linéairement, on est à 15% pour l'instant, 2024 - 2030 ça fait 7 ans, donc 15/7 = 2.15% par an en moyenne.
On obtient ainsi notre trajectoire simplifiée.


```{r}
df_traj_RE <- df_full
for (year in c(2024:2030)){
  last_row <- tail(df_traj_RE, n=1)
  last_row <- last_row %>% mutate(across(
    .cols = -c(REshare, ln_Real_GDP_per_cap),
    .fns  = ~ NaN
  ))
  last_row$Year = year 
  last_row$ln_Real_GDP_per_cap = last_row$ln_Real_GDP_per_cap + log(1.03)
  last_row$REshare = last_row$REshare + 0.0215
  df_traj_RE <- rbind(df_traj_RE, last_row)
}

df_traj_RE <- filter(df_traj_RE, Year > 2022)
```

### Bootpath


#### full joint boot

```{r}
library(boot)

joint_energy_boot <- function(data, indices, traj){

  d <- data[indices, ]

  # -------- PRICE MODEL --------
  price_fit <- try(
    lm(composit_ln_elec_P ~ REshare,
       data = d[d$Year > 2009, ]),
    silent = TRUE
  )

  if(inherits(price_fit,"try-error"))
    return(rep(NA, nrow(traj)))

  # -------- DEMAND MODEL --------
  demand_fit <- try(
    lm(ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + composit_ln_elec_P,
       data = d),
    silent = TRUE
  )

  if(inherits(demand_fit,"try-error"))
    return(rep(NA, nrow(traj)))

  # -------- DYNAMIC SIMULATION --------
  H <- nrow(traj)

  ln_price_hat <- numeric(H)
  ln_cons_hat  <- numeric(H)

  for(h in 1:H){

    # 1) predict electricity price
    ln_price_hat[h] <- predict(
      price_fit,
      newdata = data.frame(REshare = traj$REshare[h])
    )

    # 2) predict electricity consumption
    ln_cons_hat[h] <- predict(
      demand_fit,
      newdata = data.frame(
        ln_Real_GDP_per_cap = traj$ln_Real_GDP_per_cap[h],
        composit_ln_elec_P  = ln_price_hat[h]
      )
    )
  }

  return(cbind(price = ln_price_hat,
               consumption = ln_cons_hat))
}

```

```{r}
set.seed(123)

boot_res <- boot(
  data = df_full,
  statistic = joint_energy_boot,
  R = 1000,
  traj = df_traj_RE
)


```

```{r}
boot_mat <- boot_res$t
boot_mat <- boot_mat[complete.cases(boot_mat), , drop = FALSE]

H <- nrow(df_traj_RE)

price_idx <- 1:H
cons_idx  <- (H+1):(2*H)

fan_price <- t(apply(boot_mat[, price_idx], 2, quantile, probs=c(0.05,0.5,0.95)))
fan_cons  <- t(apply(boot_mat[, cons_idx], 2, quantile, probs=c(0.05,0.5,0.95)))

colnames(fan_price) <- colnames(fan_cons) <- c("lower","median","upper")

# convert from logs
fan_price_lvl <- exp(fan_price)
fan_cons_lvl  <- exp(fan_cons)

years <- df_traj_RE$Year

```


```{r}
library(ggplot2)

# Fonction réutilisable pour tracer un fan chart avec ggplot2
plot_fan_gg <- function(fan, hist_data, hist_years, forecast_years, ylab_title,
                        col_med = "#1f78b4", col_fan = rgb(0.2, 0.4, 0.8, 0.25), filename) {

  # Données historiques
  df_hist <- data.frame(
    year = hist_years,
    value = hist_data
  )

  # Données de prévision
  df_forecast <- data.frame(
    year = forecast_years,
    lower = fan[, "lower"],
    median = fan[, "median"],
    upper = fan[, "upper"]
  )

  # Graphique de base
  p <- ggplot() +
    # Bande de confiance (90 %)
    geom_ribbon(
      data = df_forecast,
      aes(x = year, ymin = lower, ymax = upper, fill = "Intervalle de confiance à 90 %"),
      alpha = 0.25
    ) +
    # Trajectoire médiane
    geom_line(
      data = df_forecast,
      aes(x = year, y = median, color = "Trajectoire médiane (bootstrap)"),
      linewidth = 1.2
    ) +
    # Données historiques
    geom_point(
      data = df_hist,
      aes(x = year, y = value, color = "Données observées"),
      size = 2
    ) +
    # Échelles de couleur et de remplissage
    scale_color_manual(
      values = c(
        "Données observées" = "black",
        "Trajectoire médiane (bootstrap)" = col_med
      )
    ) +
    scale_fill_manual(
      values = c("Intervalle de confiance à 90 %" = col_fan)
    ) +
    # Titres et labels
    labs(
      x = "Année",
      y = ylab_title,
      color = "",
      fill = "",
      title = paste("Fan chart bootstrap des", ylab_title)
    ) +
    # Thème
    theme_minimal(base_size = 14) +
    theme(
      legend.position = "top",
      legend.direction = "horizontal",
      plot.title = element_text(face = "bold", hjust = 0.5),
      panel.grid.minor = element_blank()
    )

  # Sauvegarder le graphique
  ggsave(
    filename = filename,
    plot = p,
    width = 8,
    height = 5,
    dpi = 300
  )
}


```


```{r}
# Historical sample consistent with estimation window
hist_price_data <- df_full[df_full$Year > 2009, ]

hist_years_price <- hist_price_data$Year
hist_price <- exp(hist_price_data$composit_ln_elec_P)

# Forecast years (unchanged)
forecast_years <- df_traj_RE$Year


```


```{r}
plot_fan_gg(
  fan = fan_price_lvl,
  hist_data = hist_price,
  hist_years = hist_years_price,
  forecast_years = forecast_years,
  ylab_title = "Indice de prix de l’électricité",
  filename = "fan_chart_price_REshare.pdf"
)


```

```{r}
hist_cons_data <- df_full

hist_years_cons <- hist_cons_data$Year
hist_cons <- exp(hist_cons_data$ln_C_elec_by_pop)

plot_fan_gg(
  fan = fan_cons_lvl,
  hist_data = hist_cons,
  hist_years = hist_years_cons,
  forecast_years = forecast_years,
  ylab_title = "Consommation d’électricité par habitant",
  col_med = "red",
  col_fan = rgb(0.8,0.2,0.2,0.25),
  filename = "fan_chart_consumption_REshare.pdf"
)

```

# Formating econometrics tabs
## Structural break model
```{r}
library(texreg)

d1 <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap,
  data = df
)

d2 <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P,
  data = df
)

d3 <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P + past_2009,
  data = df
)

d4 <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P*past_2009,
  data = df
)

summary(d4)


```

```{r}
texreg(
  list(d1, d2, d3, d4),

  custom.coef.map = list(
    "(Intercept)" = "Constante",
    "ln_Real_GDP_per_cap" = "PIB réel par habitant (log)",
    "ln_Real_Elec_P" = "Prix réel de l’électricité (log)",
    "past_2009" = "Rupture structurelle après 2009",
    "ln_Real_Elec_P:past_2009" = "Élasticité prix après 2009"
  ),

  custom.model.names = c(
    "PIB seul",
    "+ Prix",
    "+ Dummy 2009",
    "+ Interaction"
  ),

  caption = "Demande d’électricité avec rupture structurelle",
  label = "tab:elec_demand_break",
  stars = c(0.01, 0.05, 0.1),
  booktabs = TRUE,
  dcolumn = FALSE,
  use.packages = FALSE
)

```
## composit price model

```{r}
b1 <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap,
  data = df
)

b2 <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P,
  data = df
)

b3 <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_P_elec,
  data = df
)

b4 <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + composit_ln_elec_P,
  data = df
)

summary(b4)

```

```{r}
# b4 OLS classique
b4_ols <- b4

# b4 Newey-West lag 1
nw_vcov_b4 <- NeweyWest(b4, lag = 1, prewhite = FALSE)
nw_se_b4   <- sqrt(diag(nw_vcov_b4))
nw_p_b4    <- coeftest(b4, vcov = nw_vcov_b4)[,4]

# Créer un "dummy model" pour texreg avec mêmes coefficients mais SE NW
b4_nw <- b4
```


```{r}
texreg(
  list(b1, b2, b3, b4_ols, b4_nw),

  # Remplacer SE et p-values seulement pour le NW
  override.se = list(
    NULL, NULL, NULL, NULL, nw_se_b4
  ),
  override.pvalues = list(
    NULL, NULL, NULL, NULL, nw_p_b4
  ),

  custom.coef.map = list(
    "(Intercept)" = "Constante",
    "ln_Real_GDP_per_cap" = "PIB réel par habitant (log)",
    "ln_Real_Elec_P" = "Prix réel de l’électricité (log)",
    "ln_P_elec" = "Prix nominal de l’électricité (log)",
    "composit_ln_elec_P" = "Indice composite du prix de l’électricité"
  ),

  custom.model.names = c(
    "PIB seul",
    "Prix réel",
    "Prix nominal",
    "Indice composite (OLS)",
    "Indice composite (NW lag 1)"
  ),

  custom.note = "Le dernier modèle est présenté avec et sans correction Newey-West (lag 1).",

  caption = "Comparaison des mesures de prix dans la demande d’électricité",
  label = "tab:elec_price_measures",
  stars = c(0.01, 0.05, 0.1),
  booktabs = TRUE,
  dcolumn = FALSE,
  use.packages = FALSE,
  digits = 3
)


```

## modèle d'influence du renouvelable sur le prix de l'élec
```{r}
p1 <- lm(
  composit_ln_elec_P ~ REshare,
  data = filter(df_full, Year > 2009)
)

summary(p1)

```

```{r}
texreg(
  list(p1),

  custom.coef.map = list(
    "(Intercept)" = "Constante",
    "REshare" = "Part des renouvelables"
  ),

  custom.model.names = c("Prix de l’électricité"),

  caption = "Formation du prix de l’électricité : effet des renouvelables",
  label = "tab:price_formation_RE",
  stars = c(0.01, 0.05, 0.1),
  booktabs = TRUE,
  dcolumn = FALSE,
  use.packages = FALSE
)

```

