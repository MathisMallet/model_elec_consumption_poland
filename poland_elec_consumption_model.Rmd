---
title: "model_conso_elec_poland"
output:
  pdf_document: default
  html_document: default
date: "2026-01-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# To do : make sure data ordered by year ? order.by = data$Year, tho I think it is.
Prendre en compte le prix des autres sources d'énergie en compétition avec l'électricité
Prendre en compte le l'influence du mix énergétique sur le coût de l'électricité.
Gérer la multicolinéarité introduite avec le lag ?
Créer une fonction qui vient effectuer tous les tests pour un model et l'utiliser.

MAJ :
Voir si variable tendancielle suffisante 
Implémenter Ridge et PCA

# Modèle de la consomation d'électricité en Pologne

## Libraires
```{r}
library(openxlsx)
library(tidyverse)
library(data.table)   
library(e1071)
library(lmtest)
library(sandwich)
library(nlme)
library(dynlm)
library(corrplot)
library(car)
library(VisCollin)
library(glmnet)
library(strucchange)
library(pls)
```

## Importation des données

```{r}
df_path = "Elec_Poland.xlsx"
raw_df = read.xlsx(
  df_path,
  sheet = "Data"
)
```

```{r}
colnames(raw_df)
```

```{r}
df <- copy(raw_df)
df <- df %>% 
  mutate(C_elec_by_pop = Elec_cons / Population) %>%
  mutate(Real_GDP_per_cap = PIB / CPI / Population) %>%
  mutate(Real_Elec_P = P_elec / CPI) %>%
  mutate(ln_C_elec_by_pop = log(C_elec_by_pop)) %>%
  mutate(ln_Real_GDP_per_cap = log(Real_GDP_per_cap)) %>%
  mutate(ln_Real_Elec_P = log(Real_Elec_P))
df <- df[-nrow(df), ]
```

## Model

```{r}
model <- lm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P,
  data = df
)

summary(model)
```
Tous les indicateurs sont au vert ! Peut-être ajuster en enlevant à l'avance la dernière année incomplète.

## Analyse des résidus
Une estimastion des moindres carrés ordinaires est non biaisée seulement si les hypothèses sur les résidus sont vérifiées.

### Normalité des résidus

Théorie :
La normalité est nécessaire pour : 
- Des t-tests valides
- Des F-tests valides lorsqu'il y a peu d'échantillons

Tests:
- Graphique: QQ-plot
- Statistique: Shapiro-Wilk / Jarque-Bera

```{r}
res <- residuals(model)

qqnorm(res)
qqline(res, col = "red")

mean(res)
skewness(res)
kurtosis(res)

shapiro.test(res)
```
On observe sur le qq plot des quantiles relativement bien alignés avec la courbe théorique, suggérant une distribution proche de la loi normale. On note que l'asymétrie est faible (-0.39), avec un léger excès de kurtosis (1.41) qui indique des queues plus épaisses que pour une distribution normale.
De plus le test de Shapiro-Wilk donne une p-value d'environ 11% qui ne permet pas de rejeter l'hypothèse selon laquelle les résidus suivent une distribution normale au seuil de 5%.
Il est alors raisonnable d'admettre valide l'hypothèse selon laquelles les résidus suivent une distribution normale.

Si l'on souhaite s'assurer toutefois d'avoir des t-tests et F-tests valides (car nos données ne sont pas asymptotiquement nombreuses), on peut utiliser les erreurs robustes standards qui corrige la non-normalité et l'hétéroscédasticité :

```{r}
coeftest(model, vcov = vcovHC(model, type = "HC1"))
```
Tous est bon ici aussi (seuil 5%) et pas de grosse différence. On peut donc rester sur les résultats d'avant.

### Autocorrélation des résidus
Si il y a de l'autocorrélation des résidus, l'estimation des moindres carrés reste sans biais mais est inefficace et fausse les erreurs standards des coefficients et biaise les tests (t-tests et F-tests) avec des intervalles de confiance trop étroits. Il y a donc un risque de faux-positif (variable faussement considérée comme significative).
```{r}
dwtest(model)
pacf(res)
Box.test(res, lag = 1, type = c("Box-Pierce", "Ljung-Box"), fitdf = 0)
plot(model, which = 1)  # Résidus vs valeurs ajustées, pas d'infos évidentes
```
Le test de Durbin-Watson donne une valeur DW = 1.07 (<1.5) avec une p-value = 0.0005 (<5%) ce qui nous permet de rejeter l'hypothèse delon laquelle l'autocorrélation des résidus est nulle. Par ailleur la valeur DW = 1.07 (<2) indique une autocorrélation positive.
Le graphe de l'autocorrélation partielle indique une autocorrélation particulièrement importante pour un lag de 1, ce que le test Box-Pierce confirme avec une p-value de 0.012 (<5%) qui permet de rejeter l'hypothèse selon laquelle les résidus sont indépendant avec un lag de 1. (Attention la validité de tt ces tests est encore à vérifier)


Cela peut être corrigé de plusieurs manières :
- Faire un modèle OLS avec autocorrélation (Cochrane-Orcutt)
- Faire un modèle autorégressif, ici l'autocorrélation est particulièrement élever pour un lag de 1, un modèle AR(1) pourrait donc être adapté.
- Utiliser d'autres modèles dynamiques comme ARIMA (avec moyenne mobile) ou modèles à effets fixes (pas pertinent ici)
- Ajouter des variables (omises) qui pourraient expliquer cette tendance temporelle (on en discuté l'autre jour, à voir, je pense que c'est la première option à envisager).
- Erreurs standards de Newey-West: calcul des erreurs standards robustes à l'autocorrélation et à l'hétéroscédasticité.(Pareil qu'avant ?? je ne crois pqs)

#### Newey-West
Le prewhitening (ou "blanchiment") est une technique utilisée dans l’estimation des matrices de variance-covariance robustes (comme celle de Newey-West) pour améliorer la précision des corrections d’autocorrélation. Pour cela il y a un ajustement d'un modèle AR(p=2 ici) sur les résidus. Particulièrement pertinente dans notre cas car nous avons une autocorrélation marquée et un petit échantillon. Lag à 2 uniquement car petit échantillon. (ça peut suffir, car petit échantillon et autocorrélation légère, réellement?)
```{r}
coeftest(model, vcov = NeweyWest(model, lag = 2, prewhite = TRUE))
```
Bon signe, les erreurs standards sont légèrement plus élevées mais les coefficients ont toujours une influence significative.

#### Cochrane-Orcutt
AR permets d'avoir les coefficients de lags et de les interprétés, Cochrane-Orcutt modifie directement les coefficient du modèle (sans lag) pour les corriger de l'autocorrélation (pas ouf ?)
```{r}
model_co <- gls(ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P,
                data = df,
                correlation = corAR1(form = ~ Year))
summary(model_co)
```
```{r}
res_co <- residuals(model_co)

qqnorm(res_co)
qqline(res_co, col = "red")

mean(res_co)
skewness(res_co)
kurtosis(res_co)

shapiro.test(res_co)
```
```{r}
#dwtest(model_co)
pacf(res_co)
Box.test(res_co, lag = 1, type = c("Box-Pierce", "Ljung-Box"), fitdf = 0)
plot(model, which = 1)
```
ça ne s'améliore pas du tt, c'est comme si le modèle était le même.
#### AR1 
```{r}
model_ar1 <- dynlm(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P + L(ln_C_elec_by_pop, 1),
  data = df
  )
summary(model_ar1)
plot(model_ar1, which = 1)
```
```{r}
library(tseries)
adf.test(df[, "ln_C_elec_by_pop"])
#Pas sationnaire
```

AR1 pas fou car : la série n'est pas stationnaire (test de Dickey-Fuller), ajouter un lag implique donc que ce lag porte toute la tendance temporelle de cette série, ce qui fausse notre raisonnement économétrique de causalité. En résumé, ce modèle perd beaucoup de son intérêt. (INTERPRETATION A VERIFIER)

#AR1 MAIS QUI MARCHE
```{r}
# Add a lagged variable (you will lose 1 observation, n=33)
df <- df %>% mutate(lag_Y = lag(ln_C_elec_by_pop))

model_dynamic <- lm(ln_C_elec_by_pop ~ lag_Y + ln_Real_GDP_per_cap + ln_Real_Elec_P, data = df)
summary(model_dynamic)
# Check autocorrelation
dwtest(model_dynamic)
```
```{r}
dwtest(model_dynamic)
pacf(residuals(model_dynamic))
Box.test(residuals(model_dynamic), lag = 1, type = c("Box-Pierce", "Ljung-Box"), fitdf = 0)
plot(model_dynamic, which = 1)  # Résidus vs valeurs ajustées, pas d'infos évidentes
```


Une solution possible est de modéliser la différentielle de notre série temporelle.

```{r}
df_diff <- df[-1, ] 
df_diff$d_ln_C_elec_by_pop <- diff(df$ln_C_elec_by_pop)
df_diff$d_ln_Real_GDP_per_cap <- diff(df$ln_Real_GDP_per_cap)
df_diff$d_ln_Real_Elec_P <- diff(df$ln_Real_Elec_P)
model_diff <- dynlm(
  d_ln_C_elec_by_pop ~ d_ln_Real_GDP_per_cap + d_ln_Real_Elec_P,
  data = df_diff
)
summary(model_diff)
```

```{r}
dwtest(model_diff)
pacf(residuals(model_diff))
Box.test(residuals(model_diff), lag = 1, type = c("Box-Pierce", "Ljung-Box"), fitdf = 0)
plot(model_diff, which = 1)  # Résidus vs valeurs ajustées, pas d'infos évidentes
```
Avec le modèle différentié, plus d'autocorrélation mais des résultat de modèle pas terribles (perte d'une observable sur 34 et perte de l'information de niveau).

#### Ajout de variables liée à une évolution temporelle (To do later)

#### Conclusion autocorrélation
Newey-West permet de dire que les t-tests et les F-tests reste correcte lorsque l'échantillon est corrigé de l'autotcorrélation. Les autres méthodes ne semble pas satisfaisantes pour le moment. Rest à réaliser aussi un ajout de certaines variables liées au temps (années ?, investissement dans de l'électrique (voir batiments cf données IEA))

### Hétéroscédasticité

Important pour la validité des tests.
Ici on tests si le carré des résidus est lié aux variables explicatives (ou à leurs carrés aussi).
```{r}
bptest(model)
bptest(model, ~ ln_Real_GDP_per_cap + ln_Real_Elec_P + 
         I(ln_Real_GDP_per_cap^2) + I(ln_Real_Elec_P^2),
       data = df)
```
Des p-value qui ne rejette pas l'hypothèse l'homoscédasticité même sous un seuil de 10% ! On est tt bon !

## Multicolinéarité des variables explicatives

### Corrélation
Si on a une forte corrélation entre les varibales explicatives, la variance des estimateurs est accrue.

```{r}
correlation <- cor(df[, c("ln_Real_GDP_per_cap", "ln_Real_Elec_P")])
corrplot(cor(df[, c("ln_Real_GDP_per_cap", "ln_Real_Elec_P")]))
correlation
```
ça à l'air plutôt ok !

### VIF

```{r}
vif(model)
```
Les deux VIF sont de l'ordre de 1 ce qui montre presque aucune colinéarité entre nos variables explicatives.

### Belsley, Kuh, and Welsch (1980) et diagnostique de colinéarité (pas sûr de la fiabilité et peut-être excessif)
```{r}
colldiag(model)
```
Le plus gros indexe de condition est 3.4 << 30. Donc pas de prb de collinéarité, mais j'ai pas vraiment compris cette méthode donc à supprimer?

### Solutions (inutile dans notre cas)
#### Régression de Ridge

```{r}
X <- model.matrix(model)[, -1]
y <- df$ln_C_elec_by_pop

ridge <- glmnet(X, y, alpha = 0) #pas sûr de ce que signifie l'alpha
summary(ridge) #pas sûr de comprendre non plus
```
#### Régression en composante principale (ça je maîtrise très bieeenn)
```{r}
pca <- prcomp(X, scale. = TRUE)
summary(pca) #Là c'est juste la PCA, mais on peut régresser à partir des variables PC1 et PC2
```
## Stabilité Temporelle

### CUSUM
Pour détecter des changement de tendances structurelles sans les connaîtres
```{r}
cusum <- efp(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P,
  data = df,
  type = "OLS-CUSUM"
)

plot(cusum)
sctest(cusum, type = "CUSUM") #(vérifier l'usage)
```
Test de CUSUM ne permet pas de rejeter l'hypothèse de coefficients stables au cours du temps (courbe à l'intérieur des bornes de confiance au seuil de 5%). Il n'y a donc pas de changement structurel au cours du temps.

On extrait toutefois les max et min :
```{r}
cusum_values <- as.numeric(cusum$process)
cusum_max <- max(cusum_values)
cusum_min <- min(cusum_values)
cusum_time <- time(cusum$process)
idx_max <- which.max(cusum_values)
idx_min <- which.min(cusum_values)
year_ratio_max <- cusum_time[idx_max]
year_ratio_min <- cusum_time[idx_min]
year_ratio_max
year_ratio_min
year_converter <- function(year_ratio, df){
    round((max(df$Year)-min(df$Year))*year_ratio, digits=0) + min(df$Year)
}

year_converter(year_ratio_min, df)
year_converter(year_ratio_max, df)
which(df$Year==year_converter(year_ratio_min, df))
which(df$Year==year_converter(year_ratio_max, df))
```


###CUSUMQ
Teste la stabilité dans le temps de la variance.
```{r}
cusumsq <- efp(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P,
  data = df,
  type = "OLS-MOSUM"
)

plot(cusumsq)
sctest(cusumsq, type = "MOSUM")
```
Idem, stabilité temporelle de la variance (un peu moindre).

On extrait le Min
```{r}
cusumsq_values <- as.numeric(cusumsq$process)
cusumsq_min <- min(cusum_values)
cusumsq_time <- time(cusumsq$process)
idx_min <- which.min(cusumsq_values)
year_ratio_min <- cusumsq_time[idx_min]
year_ratio_min

year_converter(year_ratio_min, df)
```

### Test de Chow
Test s'il y a un changement de coefficient après une date donnée.
```{r}
chow_result <- sctest(
  ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P, 
  data = df, 
  type = "Chow", 
  point = 26
)

print(chow_result)
```

```{r}
fs <- Fstats(
ln_C_elec_by_pop ~ ln_Real_GDP_per_cap + ln_Real_Elec_P,
data = df
)
plot(fs)
```
mauvaise nouvelle,  le test de Chow indique des rupture de tendance un peu partout (sauf tardivement)!!!

Le plateu haut et mauvais signe et indique une non-stationarité ou un modèle mauvais presque partout ?

## Modèle dynamique 

### Stabilité temporelle

```{r}
cusum <- efp(
  ln_C_elec_by_pop ~ lag_Y + ln_Real_GDP_per_cap + ln_Real_Elec_P,
  data = df,
  type = "OLS-CUSUM"
)

plot(cusum)
sctest(cusum, type = "CUSUM") #(vérifier l'usage)
#model_dynamic
```
```{r}
fs <- Fstats(
ln_C_elec_by_pop ~ lag_Y + ln_Real_GDP_per_cap + ln_Real_Elec_P,
data = df
)
plot(fs)
```

```{r}
chow_result <- sctest(
  ln_C_elec_by_pop ~ lag_Y + ln_Real_GDP_per_cap + ln_Real_Elec_P, 
  data = df, 
  type = "Chow", 
  point = 8
)

print(chow_result)
```

## Multicolinéarité des variables explicatives

### Corrélation
Si on a une forte corrélation entre les varibales explicatives, la variance des estimateurs est accrue.

```{r}
df_lag <- df[-1,]
correlation <- cor(df_lag[, c("lag_Y","ln_Real_GDP_per_cap", "ln_Real_Elec_P")])
corrplot(cor(df_lag[, c("lag_Y","ln_Real_GDP_per_cap", "ln_Real_Elec_P")]))
correlation
```
ça à l'air plutôt ok !

### VIF

```{r}
vif(model_dynamic)
```

### Belsley, Kuh, and Welsch (1980) et diagnostique de colinéarité (pas sûr de la fiabilité et peut-être excessif)
```{r}
colldiag(model_dynamic)
```
Le plus gros indexe de condition est 30.7 ~ 30. Donc prb de collinéarité.

### Solutions 
#### Régression de Ridge

```{r}
X <- model.matrix(model_dynamic)[, -1]
y <- df_lag$ln_C_elec_by_pop

# Setting the range of lambda values
lambda_seq <- 10^seq(2, -5, by = -.1)

ridge <- glmnet(X, y, alpha = 0, lambda = lambda_seq) #pas sûr de ce que signifie l'alpha
summary(ridge) #pas sûr de comprendre non plus
```
```{r}
# Using cross validation glmnet
ridge_cv <- cv.glmnet(X, y, alpha = 0, lambda = lambda_seq)
# Best lambda value
best_lambda <- ridge_cv$lambda.min
best_lambda
```

```{r}
#best_fit <- ridge_cv$glmnet.fit
#head(best_fit)
best_ridge <- glmnet(X, y, alpha = 0, lambda = 0.001258925)
coef(best_ridge)
```

#### Régression en composante principale 
```{r}
#make this example reproducible
set.seed(1)

#fit PCR model
model <- pcr(ln_C_elec_by_pop ~ lag_Y + ln_Real_GDP_per_cap + ln_Real_Elec_P
               , data=df_lag, scale=TRUE, validation="CV")

summary(model)
validationplot(model)
validationplot(model, val.type="MSEP")
validationplot(model, val.type="R2")
```
#### TEMP
```{r}
#define training and testing sets
train <- mtcars[1:25, c("hp", "mpg", "disp", "drat", "wt", "qsec")]
y_test <- mtcars[26:nrow(mtcars), c("hp")]
test <- mtcars[26:nrow(mtcars), c("mpg", "disp", "drat", "wt", "qsec")]
    
#use model to make predictions on a test set
model <- pcr(hp~mpg+disp+drat+wt+qsec, data=train, scale=TRUE, validation="CV")
pcr_pred <- predict(model, test, ncomp=2)

#calculate RMSE
sqrt(mean((pcr_pred - y_test)^2))
```


##ARDL (Autoregressive Distributed Lag) Pas ouf ici
```{r}
model_ARDL <- lm(ln_C_elec_by_pop ~ 
                  lag(ln_C_elec_by_pop) + 
                  ln_Real_GDP_per_cap + 
                  lag(ln_Real_GDP_per_cap) + 
                  ln_Real_Elec_P +
                  lag(ln_Real_Elec_P), 
                data = df)

summary(model_ARDL)
```

## Bootstrap ?

```{r}
library(boot)

# Function to obtain R-squared
rsq <- function(formula, data, indices) {
  d <- data[indices, ]      # bootstrap sample
  fit <- lm(formula, data = d)
  return(summary(fit)$r.squared)
}

# Run bootstrapping with 1000 replications
results <- boot(
  data = df_lag,
  statistic = rsq,
  R = 1000,
  formula = ln_C_elec_by_pop ~ lag_Y + ln_Real_GDP_per_cap + ln_Real_Elec_P
)

# View results
results

# Plot bootstrap distribution
plot(results)

# 95% confidence interval (BCa)
boot.ci(results, type = "bca")
```

#### Trajectories

On peut faire plusieur trajectoires jusqu'à 2050, ici on proposera (tt les euro en réel):
- croissance de 3% du PIB (https://economy-finance.ec.europa.eu/economic-surveillance-eu-member-states/country-pages/poland/economic-forecast-poland_en)
- hard transition : prix de l'électricité + 5%/an pendant 10 ans (https://www.forum-energii.eu/en/download/download/transformacja-energetyczna-polski-edycja-2025) (pas vraiment d'info prix source)
- slow transition : prix de l'électricité + 2% jusqu'en 2050
- Chock des prix : + 100% en 2025
- Crise : PIB réel -10%
- Décroissance : -1% à partir de 2030
- Same as usual :  économie stable (prix elec, croissance +3%), autres tendances linéraires


```{r}
plot(df_lag$Year, df_lag$PIB)
plot(df_lag$Year, df_lag$Population)
plot(df_lag$Year, df_lag$CPI)
plot(df_lag$Year, df_lag$P_elec)

plot(df_lag$Year, df_lag$ln_Real_GDP_per_cap)
plot(df_lag$Year, df_lag$ln_Real_Elec_P)
```
```{r}
df_traj_stable <- df_lag
for (year in c(2024:2050)){
  last_row <- tail(df_traj_stable, n=1)
  last_row <- last_row %>% mutate(across(
    .cols = -c(ln_Real_GDP_per_cap, ln_Real_Elec_P),
    .fns  = ~ NaN
  ))
  last_row$Year = year 
  last_row$ln_Real_GDP_per_cap = last_row$ln_Real_GDP_per_cap + log(1.03)
  last_row$ln_Real_Elec_P = last_row$ln_Real_Elec_P #useless line but explicit
  df_traj_stable <- rbind(df_traj_stable, last_row)
}

#df_traj_stable <- filter(df_traj_stable, Year > 2023)
  
```



```{r}
boot_path <- function(data, indices, traj, Y0) {
  
  d <- data[indices, ]
  
  fit <- lm(
    ln_C_elec_by_pop ~ lag_Y + ln_Real_GDP_per_cap + ln_Real_Elec_P,
    data = d
  )
  
  beta <- coef(fit)
  H <- nrow(traj)
  
  Y_hat <- numeric(H)
  Y_prev <- Y0
  
  for (h in 1:H) {
    Y_hat[h] <-
      beta[1] +
      beta["lag_Y"] * Y_prev +
      beta["ln_Real_GDP_per_cap"] * traj$ln_Real_GDP_per_cap[h] +
      beta["ln_Real_Elec_P"] * traj$ln_Real_Elec_P[h]
    
    Y_prev <- Y_hat[h]  # update lag
  }
  
  return(Y_hat)
}

```

```{r}
Y0 <- tail(df_lag$ln_C_elec_by_pop, 1)

set.seed(46)

boot_results <- boot(
  data = df_lag,
  statistic = boot_path,
  R = 1000,
  traj = df_traj_stable,
  Y0 = Y0
)

```

```{r}
proj_ci <- apply(
  boot_results$t,
  2,
  quantile,
  probs = c(0.01, 0.5, 0.99)
)

proj_ci <- t(proj_ci)
colnames(proj_ci) <- c("lower", "median", "upper")
```

```{r}
H <- nrow(df_traj_stable)

plot(
  1:H, proj_ci[, "median"],
  type = "l",
  lwd = 2,
  ylim = range(proj_ci),
  xlab = "Horizon",
  ylab = "ln(C_elec_by_pop)",
  main = "Bootstrap Dynamic Projection"
)

polygon(
  c(1:H, rev(1:H)),
  c(proj_ci[, "lower"], rev(proj_ci[, "upper"])),
  col = rgb(0, 0, 1, 0.2),
  border = NA
)

```
```{r}
real_y = df_lag$ln_C_elec_by_pop
real_H = length(real_y)
H <- nrow(df_traj_stable)

ylim_all <- range(
  proj_ci[, c("lower", "upper")],
  real_y,
  na.rm = TRUE
)

plot(
  1:H, proj_ci[, "median"],
  type = "n",                     # set up canvas first
  ylim = ylim_all,
  xlab = "Horizon",
  ylab = "ln(C_elec_by_pop)",
  main = "Bootstrap Dynamic Projection with Real Data"
)

# Fan chart (confidence band)
polygon(
  c(1:H, rev(1:H)),
  c(proj_ci[, "lower"], rev(proj_ci[, "upper"])),
  col = rgb(0.2, 0.4, 0.8, 0.25),
  border = NA
)

# Median projection
lines(
  1:H, proj_ci[, "median"],
  lwd = 2,
  col = "blue"
)

# Real observed data
lines(
  1:real_H, real_y,
  lwd = 2,
  col = "black",
  lty = 1
)

# Optional: points for real data
points(
  1:real_H, real_y,
  pch = 16,
  cex = 0.7,
  col = "black"
)

# Legend
legend(
  "topleft",
  legend = c("Median projection", "90% CI", "Observed data"),
  lwd = c(2, NA, 2),
  pch = c(NA, 15, 16),
  col = c("blue", rgb(0.2, 0.4, 0.8, 0.25), "black"),
  bty = "n"
)
```

